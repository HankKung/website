<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Hank Chi-Hsi Kung</title>

    <meta name="author" content="Chi-Hsi Hank Kung">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Hank Chi-Hsi Kung 
                </p>
                
                <p>
                  I am a visiting researcher at Indiana University Bloomington where I am working with Prof. <a href="https://homes.luddy.indiana.edu/djcran/">David Crandall</a> and Prof. <a href="https://psych.indiana.edu/directory/faculty/smith-linda.html">Linda Smith</a>. My current research focuses on visual representation learning in both human and machine intelligence
                 </p>
                 <p>Previously, I was a research assistant at <a href="https://www.nycu.edu.tw/nycu/en/index">National Chiao Tung University, Taiwan</a>, and was supervised by Prof. <a href="https://sites.google.com/site/yitingchen0524/">Yi-Ting Chen</a> and Dr. <a href="https://sites.google.com/site/yihsuantsai/">Yi-Hsuan Tsai</a>.</p>
                 <p>
                  I was a research intern at IBM Thomas J. Watson Research Center. I received my M.Sc from National Tsing-Hua University, where I was supervised by Prof. <a href="http://www.cs.nthu.edu.tw/~cherung/">Che-Rung Lee</a>, and B.Sc from National Taipei University. 
                  <!-- I will be visiting CMU and work with Prof. <a href="https://davheld.github.io/">David Held</a> soon! -->
                </p>
                <p><strong>I am actively seeking a Ph.D. position!</strong></p>
                <!-- <p>  -->
                <!-- I'm currently looking for a Ph.D position for 2024 Fall! See you in ICCV Paris! -->
                <!-- </p> -->
                <p style="text-align:center">
                  <a href="mailto:hank910140@gmail.com">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com.tw/citations?user=qdyuCMQAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/7ckung">X</a> &nbsp;/&nbsp;
                  <a href="https://github.com/HankKung">Github</a>&nbsp;/&nbsp;
                  <a href="https://drive.google.com/file/d/1cDmjVHeCq53s9GwMM6pBGsg5Avpe6t2j/view">CV</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a><img style="max-width: 100%; height: auto;" alt="profile photo" src="images/headshot.JPG" class="hoverZoomLink"></a>
              </td>

            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research Interests</h2>
                <p>
                  I am interested in developing <strong>Human-Like AI</strong> that can generalize from limited data or experience by reverse-engineering human cognition‚Äîsuch as <strong>Intuitive Physics</strong>‚Äîand leveraging insights from cognitive science and developmental psychology. 
                  To make progress on exploring the core ingredients of human-like AI, my research focuses on:
                </p>
                <ul>
                  <li><a href="https://openaccess.thecvf.com/content/CVPR2024/html/Kung_Action-slot_Visual_Action-centric_Representations_for_Multi-label_Atomic_Activity_Recognition_in_CVPR_2024_paper.html">Learning compositional representations that can be "reused" and be "augmentable"</a></li>
                  <li>Modeling human learning mechanisms inspired by cognitive science</li>
                  <li><a href="https://arxiv.org/abs/2503.21055">Enabling robots to see, think, and learn like humans</a></li>
                  <li>Developing intuitive physics for world models</li>
                </ul>
              </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Workshop Organizing</h2>
                <p>Organizing <a href="https://sites.google.com/view/reverse-engineeringhumanlearn/home">Reverse-Engineering Human's Learning Mechanisms: Toward Human-Like AI</a> at <strong>NeurIPS 2025</strong> </p>

                <p><a href="https://sites.google.com/view/road-eccv2024/home?authuser=0">3rd ROAD++ Workshop & Challenge of Compositional Representation for Traffic Activities</a> at <strong>ECCV 2024</strong></p>
              </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>

            <td style="padding:20px;width:40%;vertical-align:middle;height: 30px;">
              <h2>Publications</h2>
            </td>
            </tr>

          <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="images/view_selection.png" width=100% height=100%>
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
                <span class="papertitle">Learning to Look Like Humans: Modeling Planar View Bias with Inductive Priors in Reinforcement Learning</span>
              <br>
              <br>
              <strong>Chi-Hsi Kung</strong>, 
              <a href="https://sites.google.com/view/frangilramirez/home">Frangil Ramirez</a>, 
              <a href="https://scholar.google.com/citations?user=6NjrfvkAAAAJ&hl=en">Juhyung Ha</a>,
              <a href="https://sites.google.com/site/yitingchen0524">Yi-Ting Chen</a>,
              <a href="https://homes.luddy.indiana.edu/djcran/">David Crandall</a>,
              <a href="https://psych.indiana.edu/directory/faculty/smith-linda.html">Linda Smith</a>
              <p>
              <a>Paper coming soon</a>
              /
              <a>Code coming soon</a>
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="images/counterfactual.gif" width=100% height=100%>
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
                <span class="papertitle">What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning</span>
              <br>
              <br>
              <strong>Chi-Hsi Kung</strong>*, 
              <a href="https://sites.google.com/view/frangilramirez/home">Frangil Ramirez*</a>, 
              <a href="https://scholar.google.com/citations?user=6NjrfvkAAAAJ&hl=en">Juhyung Ha</a>,
              <a href="https://sites.google.com/site/yihsuantsai/">Yi-Hsuan Tsai</a>, 
              <a href="https://sites.google.com/site/yitingchen0524">Yi-Ting Chen</a>,
              <a href="https://homes.luddy.indiana.edu/djcran/">David Crandall</a>
               (* Equal Contribution)</a>
              <br>
              <em>Under review</em>
              <br>
              <a href="https://arxiv.org/abs/2503.21055">arxiv</a>
              /
              <a>Code coming soon</a>

            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="images/ATARS.png" width=100% height=100%>
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <a href="https://hcis-lab.github.io/Action-slot/"> -->
                <span class="papertitle">ATARS: An Aerial Traffic Atomic Activity Recognition and Temporal Segmentation Dataset</span>
              <!-- </a> -->
              <br>
              <br>
              <a>Zihao Chen</a>, 
              <a>Hsuanyu Wu</a>, 
              <strong>Chi-Hsi Kung</strong>*, 
              <a href="https://sites.google.com/site/yitingchen0524">Yi-Ting Chen*</a>,
              <a href="https://www.cs.nccu.edu.tw/~ytpeng/">Yan-Tsung Peng*</a>
               (* Equal Advising)</a>
              <br>
              <em>Under review</em>
              <br>
              <!-- <a href="https://hcis-lab.github.io/Action-slot/">project page</a>
              / -->
              <a href="https://arxiv.org/abs/2503.18553">arxiv</a>
              <!-- / -->
              <!-- <a href="https://arxiv.org/abs/2311.17948">arxiv</a> -->
              /
              <a href="https://github.com/magecliff96/ATARS/">Code</a>
              /
              <!-- <a href="https://nycu1-my.sharepoint.com/:f:/g/personal/ychen_m365_nycu_edu_tw/EnRg1zT7CeZGg3Ju2TIP1j8B0NB0fCpYsjGQBc0Tcf2H6w?e=FGJvTc">TACO dataset</a> -->

            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="images/scenario_generation.png" width=100% height=100%>
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <a href="https://hcis-lab.github.io/Action-slot/"> -->
                <span class="papertitle">Controllable Scenario-based Collision Generation for Safety Assessment</span>
              <!-- </a> -->
              <br>
              <br>
              <a>Pin-Lun Chen</a>, 
              <strong>Chi-Hsi Kung</strong>, 
              <a href="https://scholar.google.com/citations?user=LLoPMDMAAAAJ&hl=en">Che-Han Chang</a>,
              <a href="https://walonchiu.github.io/">Wei-Chen Chiu</a>,
              <a href="https://sites.google.com/site/yitingchen0524">Yi-Ting Chen</a>
              <br>
              <em>Under review</em>
              <br>
              <!-- <a href="https://hcis-lab.github.io/Action-slot/">project page</a>
              / -->
              <a>Paper coming soon</a>
              <!-- / -->
              <!-- <a href="https://arxiv.org/abs/2311.17948">arxiv</a> -->
              /
              <a>Code coming soon</a>
            </td>
          </tr>


            <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="images/action-slot.gif" width=100% height=100%>
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <a href="https://hcis-lab.github.io/Action-slot/"> -->
                <span class="papertitle">Action-slot: Visual Action-centric Representations for Atomic Activity Recognition in Traffic Scenes</span>
              <!-- </a> -->
              <br>
              <br>
              <strong>Chi-Hsi Kung</strong>, 
              <a>Shu-Wei Lu</a>, 
              <a href="https://sites.google.com/site/yihsuantsai/">Yi-Hsuan Tsai</a>, 
              <a href="https://sites.google.com/site/yitingchen0524">Yi-Ting Chen</a>
              <br>
              <em>CVPR</em>, 2024
              <br>
              <a href="https://hcis-lab.github.io/Action-slot/">project page</a>
              /
              <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Kung_Action-slot_Visual_Action-centric_Representations_for_Multi-label_Atomic_Activity_Recognition_in_CVPR_2024_paper.html">paper</a>
              /
              <a href="https://arxiv.org/abs/2311.17948">arxiv</a>
              /
              <a href="https://github.com/HCIS-Lab/Action-slot/tree/main">code</a>
              /
              <a href="https://nycu1-my.sharepoint.com/:f:/g/personal/ychen_m365_nycu_edu_tw/EnRg1zT7CeZGg3Ju2TIP1j8B0NB0fCpYsjGQBc0Tcf2H6w?e=FGJvTc">TACO dataset</a>
            </td>
      </tr>

      <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="images/riskbench.gif" width=100% height=100%>
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <a href="https://hcis-lab.github.io/RiskBench/"> -->
                <span class="papertitle">RiskBench: A Scenario-based Benchmark for Risk Identification</span>
              <!-- </a> -->
              <br>
              <br>
              <strong>Chi-Hsi Kung</strong>, 
              <a>Chieh-Chi Yang</a>, 
              <a>Pang-Yuan Pao</a>, 
              <a>Shu-Wei Lu</a>, 
              <a>Pin-Lun Chen</a>, 
              <a>Hsin-Cheng Lu</a>, 
              <a href="https://sites.google.com/site/yitingchen0524">Yi-Ting Chen</a>
              <br>
              <em>ICRA</em>, 2024
              <br>
              <a href="https://hcis-lab.github.io/RiskBench/">project page</a>
              /
              <a href="https://www.youtube.com/watch?v=9VQV7TRmwl4">video</a>
              /
              <a href="https://arxiv.org/abs/2312.01659">paper</a>
              /
              <a href="https://github.com/HCIS-Lab/RiskBench">code</a>
              /
              <a href="https://nycu1-my.sharepoint.com/personal/ychen_m365_nycu_edu_tw/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fychen%5Fm365%5Fnycu%5Fedu%5Ftw%2FDocuments%2FRiskBench&ga=1">dataset</a>
            </td>
      </tr>
      <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
  <!--               <div class="one">
                <div class="two" id='bakedsdf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/bakedsdf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/bakedsdf_before.jpg' width="160">
              </div> -->
                 <!-- <div class="content has-text-justified">
                 <img src="images/ADD.png">
                 </d -->
                 <img src="images/ADD.png" width=100% height=100%>
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <!-- <a href="https://ieeexplore.ieee.org/document/9636650"> -->
                <span class="papertitle">ADD: A Fine-grained Dynamic Inference Architecture for Semantic Image Segmentation</span>
              <!-- </a> -->
              <br>
              <br>
              <strong>Chi-Hsi Kung</strong> and
              <a href="http://www.cs.nthu.edu.tw/~cherung/">Che-Rung Lee</a>
              <br>
              <em>IROS</em>, 2021 & <a href="https://mrvc-2021.net/">ACML 2021 MRVC workshop</a>
              <br>
              <a href="https://ieeexplore.ieee.org/document/9636650">paper</a>
              /
              <a href="https://github.com/HankKung/Auto-Dynamic-DeepLab">code</a>
            </td>
      </tr>
          </tbody>
        </table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Conference Reviewer</h2>
                
                <p>IEEE Conference on Computer Vision and Pattern Recognition <strong>CVPR</strong> 2023-2025</p>
                <p>The International Conference on Machine Learning <strong>ICML</strong> 2025</p>
                <p>International Conference on Computer Vision <strong>ICCV</strong> 2025</p>
                <p>Advances in Neural Information Processing Systems <strong>NeurIPS</strong> 2024</p>
                <p>IEEE International Conference on Development and Learning <strong>ICDL</strong> 2024</p>
                <p>IEEE/RSJ International Conference on Intelligent Robots and Systems <strong>IROS</strong> 2025</p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Invited Talk</h2>
                <p><a href="https://cvgip2024.csie.ndhu.edu.tw/agenda/forum/">CVGIP 2024</a></p>
              </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>


