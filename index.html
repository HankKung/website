<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Chi-Hsi Hank Kung</title>

    <meta name="author" content="Chi-Hsi Hank Kung">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:1100px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Chi-Hsi Hank Kung 
                </p>
                <p>I am a research assistant at National Yang Ming Chiao Tung University</a> in Taiwan</a>, where I work on visual action recognition and event identification in traffic scenes and advised by Prof. <a href="https://sites.google.com/site/yitingchen0524/">Yi-Ting Chen</a>. Meanwhile, I am also actively cooperating with Dr. <a href="https://sites.google.com/site/yihsuantsai/">Yi-Hsuan Tsai</a>. Prior to this, I received my M.Sc from National Tsing-Hua University supervised by Prof. <a href="http://www.cs.nthu.edu.tw/~cherung/">Che-Rung Lee</a>. and B.Sc degrees from National Taipei University. 
                  <!-- I will be visiting CMU and work with Prof. <a href="https://davheld.github.io/">David Held</a> soon! -->
                </p>
                <p> 
                I'm currently looking for a Ph.D position for 2024 Fall! See you in ICCV Paris!
                </p>
                <p style="text-align:center">
                  <a href="mailto:chkung@nycu.edu.tw">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com.tw/citations?user=qdyuCMQAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/7ckung">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/HankKung">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/hank.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/hank.JPG" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>


          <<!-- table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <p>
                  I am a dog person too! I am blessed to have my poodle <a href="https://instagram.com/emmaisapoodle?igshid=MzRlODBiNWFlZA==">Emma</a> to bring joy into my life. Feel free to check her out!
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/emma1.gif"><img style="width:50%;max-width:50%" alt="profile photo" src="images/emma1.gif" class="hoverZoomLink"></a>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/emma2.gif"><img style="width:50%;max-width:50%" alt="profile photo" src="images/emma2.gif" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table> -->

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p>
              I am a dog person too! I am blessed to have my poodle <a href="https://instagram.com/emmaisapoodle?igshid=MzRlODBiNWFlZA==">Emma</a> to bring joy into my life. Feel free to check her out!
              </p>
            </td>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="images/emma1.gif" width=100% height=100%>
            </td>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="images/emma2.gif" width=100% height=100%>
            </td>
      </tr>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research interest is generally building machine learning system to automatically analyze visual data, particularly in videos. My primary research direction focuses on learning visual action-centric representation that can improve action recognition and event identification. More broadly, I'm also interested in using such compact action-centric representations to facilitate reasoning for robot learning from human demonstration videos. I have rich experimence of defining problems/tasks and creating systematic datasets/benchmarks for traffic scenes. Feel free to contact me if you have any issue on these topic!
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
              <img src="images/action-slot.gif" width=100% height=100%>
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://hcis-lab.github.io/Action-slot/">
                <span class="papertitle">Action-slot: Visual Action-centric Representation for Traffic Pattern Recognition</span>
              </a>
              <br>
              <strong>Chi-Hsi Kung</strong>,
              <a href="">Shu-Wei Lu</a>
              <a href="https://sites.google.com/site/yihsuantsai/">Yi-Hsuan Tsai</a>
              <a href="https://sites.google.com/site/yitingchen0524">Yi-Ting Chen</a>
              <br>
              <em>arxiv</em>, 2023
              <br>
              <a href="https://hcis-lab.github.io/Action-slot/">project page</a>
              /
              <a href="">paper coming soon</a>
              /
              <a href="">code coming soon</a>
              /
              <a href="">TACO dataset coming soon</a>
              /
              <a href="">ROAD dataset coming soon</a>
              <p>
              Action-slot can localize traffic pattern in a weakly-supervised manner. The learned action-centric representation is aware of the occurrence of a traffic pattern/event/action (e.g., see the pedestrian on sidewalk).
              </p>
            </td>
      </tr>
      <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
  <!--               <div class="one">
                <div class="two" id='bakedsdf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/bakedsdf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/bakedsdf_before.jpg' width="160">
              </div> -->
<!--               <div class="content has-text-justified">
                <img src="images/ADD.png">
              </div> --> 
              <img src="images/riskbench.gif" width=100% height=100%>
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://hcis-lab.github.io/RiskBench/">
                <span class="papertitle">RiskBench: A Scenario-based Benchmark for Risk Identification</span>
              </a>
              <br>
              <strong>Chi-Hsi Kung</strong>,
              <a href="">Chieh-Chi Yang</a>
              <a href="">Pang-Yuan Pao</a>
              <a href="">Shu-Wei Lu</a>
              <a href="">Pin-Lun Chen</a>
              <a href="">Hsin-Cheng Lu</a>
              <a href="https://sites.google.com/site/yitingchen0524">Yi-Ting Chen</a>
              <br>
              <em>arxiv</em>, 2023
              <br>
              <!-- a href="https://ieeexplore.ieee.org/document/9636650">paper</a>
              / -->
              <a href="https://hcis-lab.github.io/RiskBench/">project page</a>
              /
              <a href="https://www.youtube.com/watch?v=9VQV7TRmwl4">video</a>
              /
              <a href="">paper coming soon</a>
              /
              <a href="https://github.com/HCIS-Lab/RiskBench">code</a>
              /
              <a href="https://nycu1-my.sharepoint.com/personal/ychen_m365_nycu_edu_tw/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fychen%5Fm365%5Fnycu%5Fedu%5Ftw%2FDocuments%2FRiskBench&ga=1">dataset</a>
              <p>
              We benchmark 10 risk identification methods on 4 interaction types scenarios: interactive, collision, obstacle, and non-interactive. We also design evaluation metrics for risk localization, anticpation, temporal consistency, and planning-awareness.
              </p>
            </td>
      </tr>
      <tr>
            <td style="padding:20px;width:40%;vertical-align:middle">
  <!--               <div class="one">
                <div class="two" id='bakedsdf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/bakedsdf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/bakedsdf_before.jpg' width="160">
              </div> -->
                 <!-- <div class="content has-text-justified">
                 <img src="images/ADD.png">
                 </d -->
                 <img src="images/ADD.png" width=100% height=100%>
            </td>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9636650">
                <span class="papertitle">ADD: A Fine-grained Dynamic Inference Architecture for Semantic Image Segmentation</span>
              </a>
              <br>
              <strong>Chi-Hsi Kung</strong>,
              <a href="http://www.cs.nthu.edu.tw/~cherung/">Che-Rung Lee</a>
              <br>
              <em>IROS</em>, 2021
              <br>
              <a href="https://ieeexplore.ieee.org/document/9636650">paper</a>
              /
              <a href="https://github.com/HankKung/Auto-Dynamic-DeepLab">code</a>
              <p>
              We use Neural Architecture Search (NAS) to find an optimal structure for dynamic inference on semantic segmentation.
              </p>
            </td>
      </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>


